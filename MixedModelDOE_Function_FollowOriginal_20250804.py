import pandas as pd
import numpy as np
from itertools import combinations
import statsmodels.formula.api as smf
from statsmodels.stats.anova import anova_lm
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from patsy import dmatrix
from statsmodels.stats.outliers_influence import OLSInfluence
from scipy.stats import f
import warnings
warnings.filterwarnings("ignore")

# import os
from statsmodels.formula.api import mixedlm
from statsmodels.tools.sm_exceptions import ConvergenceWarning
warnings.simplefilter("ignore", ConvergenceWarning)
import os

def run_mixed_model_doe(file_path, output_dir):
    """
    å®Œå…¨åŸºäºåŸå§‹è„šæœ¬çš„DOEæ··åˆæ¨¡å‹åˆ†æå‡½æ•°
    ä¿æŒæ‰€æœ‰åŸå§‹é€»è¾‘ã€æ³¨é‡Šå’Œç»“æ„ä¸å˜
    """
    
    # === 1. æ•°æ®å¯¼å…¥ ===
    df_raw = pd.read_csv(file_path)
    response_vars = ["Lvalue", "Avalue", "Bvalue"]
    predictors = ["dye1", "dye2", "Time", "Temp"]

    # === 2. æ ‡å‡†åŒ–ç”¨äº simplified æ¨¡å‹å»ºæ¨¡ ===
    scaler = StandardScaler()
    df = df_raw.copy()
    df[predictors] = scaler.fit_transform(df[predictors])

    print("âœ… DEBUG: df shape =", df.shape)
    print("ğŸ“ df å‡å€¼ï¼š")
    print(df[["Temp", "Time", "dye1", "dye2"]].mean(), flush=True)
    print("ğŸ“ df æ ‡å‡†å·®ï¼š")
    print(df[["Temp", "Time", "dye1", "dye2"]].std(ddof=0), flush=True)

    print("ğŸ“ Part 2 æ„å»º X_coded æ—¶çš„åŸå§‹å‡å€¼ä¸æ ‡å‡†å·®ï¼š")
    print("X_mean =", scaler.mean_)
    print("X_std  =", scaler.scale_)

    # === 3. æ„é€  RSM é¡¹ ===
    def create_rsm_terms(terms):
        linear = terms
        square = [f"I({t}**2)" for t in terms]
        inter = [f"{a}:{b}" for a, b in combinations(terms, 2)]
        return linear + square + inter

    rsm_terms = create_rsm_terms(predictors)

    # === 4. å…¨æ¨¡å‹ LogWorth æ‰«æ ===
    effect_summary_all = pd.DataFrame()
    for y in response_vars:
        formula = f"{y} ~ " + " + ".join(rsm_terms)
        model = smf.ols(formula, data=df).fit()
        anova_tbl = anova_lm(model, typ=3).reset_index()
        anova_tbl = anova_tbl.rename(columns={"index": "Factor"})
        anova_tbl = anova_tbl[anova_tbl["Factor"] != "Residual"]
        anova_tbl["LogWorth"] = -np.log10(anova_tbl["PR(>F)"].replace(0, 1e-16))
        temp = anova_tbl[["Factor", "LogWorth"]].copy()
        temp.columns = ["Factor", y]
        effect_summary_all = pd.merge(effect_summary_all, temp, on="Factor", how="outer") if not effect_summary_all.empty else temp

    effect_summary_all = effect_summary_all.fillna(0)
    effect_summary_all["Median_LogWorth"] = effect_summary_all[response_vars].median(axis=1)
    effect_summary_all["Max_LogWorth"] = effect_summary_all[response_vars].max(axis=1)
    effect_summary_all["Appears_Significant"] = (effect_summary_all[response_vars] > 1.3).sum(axis=1)
    effect_summary_all = effect_summary_all.sort_values("Max_LogWorth", ascending=False)

    # === 5. ç­›é€‰ç®€åŒ–å› å­ï¼ˆä¿æŒ hierarchyï¼‰===
    def get_simplified_factors(effect_matrix, threshold=1.3, min_significant=2):
        factors = effect_matrix[
            (effect_matrix["Max_LogWorth"] >= threshold) | 
            (effect_matrix["Appears_Significant"] >= min_significant)
        ]["Factor"].tolist()
        if "Intercept" in factors:
            factors.remove("Intercept")
        hierarchical_terms = set(factors)
        for f in factors:
            if ":" in f:
                a, b = f.split(":")
                hierarchical_terms |= {a.strip(), b.strip()}
            if "I(" in f:
                base = f.split("(")[1].split("**")[0].strip()
                hierarchical_terms.add(base)
        return sorted(hierarchical_terms)

    simplified_factors = get_simplified_factors(effect_summary_all)

    # === 6. æ„é€ åŸå§‹ Config é”®å€¼ï¼ˆJMP å¯¹é½ï¼‰===
    df_raw["Config_combo"] = df_raw[["dye1", "dye2", "Time", "Temp"]].astype(str).agg("_".join, axis=1)
    df["Config_combo"] = df_raw["Config_combo"]

    # === 7. å…±çº¿æ€§æ£€æŸ¥ ===
    try:
        x = dmatrix(" + ".join(simplified_factors), data=df, return_type="dataframe")
        xtx = x.T @ x
        condition_number = np.linalg.cond(xtx.values)
        print(f"\nğŸ“ Alias Check â€“ X'X condition number: {condition_number:.2f}")
    except Exception as e:
        print(f"\nâŒ Error building design matrix: {str(e)}")


    # === 8. æ‰“å°è¾“å‡ºï¼šFull Model + Simplified Model LogWorth ===
    print("\nğŸ“Š Combined Effect Summary (Full Model â€“ LogWorth):")
    print(effect_summary_all)

    print("\nâœ… Suggested Simplified Factors (with hierarchy):")
    print(simplified_factors)

    print(f"\nğŸ“ Alias Check â€“ X'X condition number: {condition_number:.2f}")

    # æ„å»º simplified_logworth_df
    simplified_logworth_df = pd.DataFrame()
    for y in response_vars:
        print(f"\nğŸ” Building simplified model for: {y}")
        formula = f"{y} ~ " + " + ".join(simplified_factors)
        model = smf.ols(formula=formula, data=df).fit()
        anova_tbl = anova_lm(model, typ=3).reset_index()
        anova_tbl = anova_tbl.rename(columns={"index": "Factor"})
        anova_tbl = anova_tbl[anova_tbl["Factor"] != "Residual"]
        anova_tbl["LogWorth"] = -np.log10(anova_tbl["PR(>F)"].replace(0, 1e-16))
        temp = anova_tbl[["Factor", "LogWorth"]].copy()
        temp.columns = ["Factor", y]
        simplified_logworth_df = pd.merge(simplified_logworth_df, temp, on="Factor", how="outer") if not simplified_logworth_df.empty else temp

    simplified_logworth_df = simplified_logworth_df.fillna(0)
    simplified_logworth_df["Median_LogWorth"] = simplified_logworth_df[response_vars].median(axis=1)
    simplified_logworth_df["Max_LogWorth"] = simplified_logworth_df[response_vars].max(axis=1)
    simplified_logworth_df["Appears_Significant"] = (simplified_logworth_df[response_vars] > 1.3).sum(axis=1)
    simplified_logworth_df = simplified_logworth_df.sort_values("Max_LogWorth", ascending=False)

    print("\nğŸ“Š Simplified Model â€“ Combined Effect Summary (LogWorth):")
    print(simplified_logworth_df)



    """
    =========================================================================================
    Part 2ï¼šå»ºæ¨¡ä¸è¯Šæ–­é€»è¾‘ï¼ˆåŸºäº Mixed Modelï¼‰
    -----------------------------------------------------------------------------------------

    æœ¬è„šæœ¬åŸºäº statsmodels çš„ MixedLMï¼ˆæ··åˆæ•ˆåº”æ¨¡å‹ï¼‰å¯¹æ¯ä¸ªå“åº”å˜é‡åˆ†åˆ«æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

    1. æ„å»ºæ··åˆæ¨¡å‹ï¼š
       - ä½¿ç”¨ formula æ„é€ å“åº”å˜é‡ä¸ç®€åŒ–å› å­ä¹‹é—´çš„å›ºå®šæ•ˆåº”å…³ç³»ï¼›
       - å°† Config_combo æŒ‡å®šä¸ºåˆ†ç»„ç»“æ„ï¼ˆç¾¤ä½“å±‚çº§çš„éšæœºæ•ˆåº”ï¼‰ï¼›
       - ä½¿ç”¨ REML æ–¹æ³•æ‹Ÿåˆæ¨¡å‹ä»¥æé«˜ä¼°è®¡ç¨³å®šæ€§ã€‚

    2. è·å–é¢„æµ‹å€¼ä¸æ®‹å·®ï¼š
       - è·å– MixedLM çš„æ‹Ÿåˆé¢„æµ‹å€¼ï¼ˆfittedvaluesï¼‰ï¼›
       - è®¡ç®— residual = çœŸå®å€¼ - é¢„æµ‹å€¼ï¼Œç”¨äºæ¨¡å‹è¯¯å·®è¯„ä¼°ã€‚

    3. è¿‘ä¼¼è®¡ç®—æ¨¡å‹è¯Šæ–­æŒ‡æ ‡ï¼ˆå›  MixedLM æ— åŸç”Ÿæä¾›ï¼‰ï¼š
       - RÂ² Approximateï¼š
           ä½¿ç”¨æ€»å¹³æ–¹å’Œ (TSS) ä¸æ®‹å·®å¹³æ–¹å’Œ (RSS) æ‰‹åŠ¨è®¡ç®—è§£é‡Šç‡ï¼›
       - Adjusted RÂ² Approximateï¼š
           åŸºäºå›ºå®šæ•ˆåº”æ•°é‡ï¼Œä¿®æ­£è¿‘ä¼¼ RÂ² ä»¥é˜²è¿‡æ‹Ÿåˆï¼›
       - RMSEï¼š
           æ ‡å‡†æ®‹å·®çš„å‡æ–¹æ ¹ï¼Œç”¨äºè¯„ä¼°ç»å¯¹é¢„æµ‹è¯¯å·®ã€‚

    4. æ‰§è¡Œ JMP é£æ ¼ Lack-of-Fit åˆ†æï¼ˆè¿‘ä¼¼é‡æ„ï¼‰ï¼š
       - MixedLM ä¸æä¾›åŸç”Ÿçš„ LOF æ£€éªŒï¼›
       - æ­¤å¤„ä½¿ç”¨ post-hoc æ–¹æ³•æ¨¡æ‹Ÿ JMP ä¸­ LOF åˆ†è§£æ€è·¯ï¼š
           - å°† Config_combo çœ‹ä½œå®éªŒé…ç½®å•å…ƒï¼›
           - æœ¬åœ°å‡å€¼ä¸é¢„æµ‹å€¼ä¹‹é—´çš„è¯¯å·®è§†ä½œ Lack-of-Fitï¼›
           - ç»„å†…é‡å¤æµ‹é‡çš„æ³¢åŠ¨è§†ä½œ Pure Errorï¼›
           - æ„å»º MS_Lack / MS_Pure çš„ F æ¯”å€¼å¹¶è®¡ç®— P å€¼ï¼›
       - æ‰€å¾—ç»“æœä¸º"JMP-style LOF Approximation"ï¼Œå¯ä¸ JMP ä¸­å…¬å¼è§£ææ³•å¯¹ç…§ã€‚

    âš ï¸ è¡¥å……è¯´æ˜ï¼š
    ç”±äº MixedLM æ— å¸½å­çŸ©é˜µï¼ˆHat matrixï¼‰ï¼Œä¹Ÿæœªæä¾› influence å‡½æ•°æ¥å£ï¼Œ
    å› æ­¤æ— æ³•è·å¾—çœŸå®ç»Ÿè®¡æ„ä¹‰ä¸Šçš„ Studentized Residualã€‚

    æˆ‘ä»¬å°†åœ¨ Part 3a ä¸­ä½¿ç”¨ï¼š
        Pseudo_Studentized_Residual = Residual / RMSE
    ä½œä¸ºå¯è§†åŒ–æ›¿ä»£ï¼Œå‘½åä¸­æ˜ç¡®æ ‡è®°ä¸º "Pseudo"ï¼Œä¾›è¯Šæ–­å›¾å‚è€ƒä½¿ç”¨ã€‚
    =========================================================================================
    """

    models = {}
    param_coded_list = []
    param_uncoded_list = []
    diagnostics_summary = []
    var_records = []  # ğŸ†• ç”¨äºæ”¶é›†æ¯ä¸ªå“åº”å˜é‡çš„ Group Var å’Œ Residual Var
    lof_records = []

    for y in response_vars:
        try:
            # ğŸ”§ æ„å»º Mixed Modelï¼ˆå« Config_combo ä¸ºéšæœºç»„å˜é‡ï¼‰
            formula = f"{y} ~ " + " + ".join(simplified_factors)
            model = mixedlm(formula, data=df, groups=df["Config_combo"])
            model_fit = model.fit(reml=True)
            # ğŸ“Š Variance Componentsï¼ˆç”¨äº Part 5ã€JMP Profiler å¯¹æ¯”ï¼‰
            group_var = model_fit.cov_re.iloc[0, 0] if model_fit.cov_re.shape[0] > 0 else np.nan
            residual_var = model_fit.scale  # == RMSEÂ²
            print(f"\nğŸ“Š Variance Components for {y}:")
            print(f" - Group Var (Config)   = {group_var:.4f}")
            print(f" - Residual Var (Error) = {residual_var:.4f}   (RMSE â‰ˆ {np.sqrt(residual_var):.4f})")

            var_records.append({
                "Response": y,
                "Group_Var": group_var,
                "Residual_Var": residual_var,
                "RMSE_from_Var": np.sqrt(residual_var)
            })

            models[y] = model_fit

            # ======================================================================================
            # ğŸ“Œã€å…³é”®è¯´æ˜ã€‘åŠ è½½ coded Î² ç³»æ•°æ—¶ï¼Œç”¨ fixed_intercepts.csv ä¸­çš„ Î²â‚€ æ›¿æ¢é»˜è®¤ Intercept
            #
            # ğŸ’¬ èƒŒæ™¯ï¼š
            # é»˜è®¤çš„ coded_parameters.csv ä¸­ Interceptï¼ˆÎ²â‚€ï¼‰å­—æ®µå¯¼å‡ºè‡ª model_fit.params["Intercept"]ï¼Œ
            # è€Œè¯¥å€¼é€šå¸¸åŒ…å«ç»„åˆ« shrinkageï¼ˆå³ group-level intercept correctionï¼‰ï¼Œéçº¯å›ºå®šé¡¹ï¼›
            #
            # ğŸ”¬ å¦‚æœç»§ç»­ä½¿ç”¨è¯¥ Interceptï¼Œä¼šå¯¼è‡´ predict_coded(...) çš„ç»“æœä¸ JMP Profiler äº§ç”Ÿæ˜æ˜¾åå·®ï¼ˆæœ€å¤šå¯è¾¾ 1.2+ï¼‰ï¼›
            # ğŸ“ˆ ä¸ºäº†ç¡®ä¿è¯„åˆ†ä¸æ¨èä¸ JMP ä¸€è‡´ï¼Œæˆ‘ä»¬éœ€å°†å…¶æ›¿æ¢ä¸º model_fit.fe_params["Intercept"] å¯¼å‡ºçš„å›ºå®šæˆªè·ã€‚
            #
            # âœ… æœ¬å‡½æ•°å°†ä¿®æ­£ Interceptï¼Œå¹¶è¿”å›ç”¨äº L/A/B æ‰“åˆ†çš„ Î² ç³»æ•°è¡¨ã€‚
            # ======================================================================================

            def load_betas(path, intercept_path):
                df = pd.read_csv(path)
                intercept_df = pd.read_csv(intercept_path)

                beta_dict = {}
                for resp in df["Response"].unique():
                    temp = df[df["Response"] == resp].copy()
                    fixed_b0 = intercept_df.loc[intercept_df["Response"] == resp, "Fixed_Intercept"].values[0]
                    temp.loc[temp["Factor"] == "Intercept", "Coef."] = fixed_b0  # â¬…ï¸ æ›¿æ¢ä¸ºçº¯ fixed intercept
                    beta_dict[resp] = dict(zip(temp["Factor"], temp["Coef."]))
                return beta_dict

            y_true = df[y]
            y_pred = model_fit.fittedvalues
            resid = y_true - y_pred

            # ğŸ¯ è¿‘ä¼¼ RÂ²ï¼ˆexternal approximationï¼‰
            # æ³¨æ„ï¼šMixedLM æ—  RÂ² åŸç”Ÿè¾“å‡ºï¼Œå› æ­¤è¿™é‡ŒåŸºäºé¢„æµ‹å€¼ä½¿ç”¨è§£é‡Šæ–¹å·®æ¯”è¿‘ä¼¼æ¨ç®—ï¼š
            ss_total = np.sum((y_true - y_true.mean()) ** 2)
            ss_resid = np.sum((y_true - y_pred) ** 2)
            r_squared = 1 - ss_resid / ss_total

            # ğŸ¯ Adjusted RÂ² è¿‘ä¼¼ï¼ˆåŸºäºå›ºå®šæ•ˆåº”è‡ªç”±åº¦ä¿®æ­£ï¼‰
            k = model_fit.k_fe - 1
            n = len(y_true)
            adj_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - k - 1)
            rmse = np.sqrt(np.mean(resid ** 2))

            diagnostics_summary.append({
                "Response": y,
                "R2_Approximate": r_squared,
                "Adjusted_R2_Approximate": adj_r_squared,
                "RMSE": rmse,
                "Mean_Response": y_true.mean(),
                "Observations": n
            })

            # ğŸ”¢ è§£æå›ºå®šæ•ˆåº”å‚æ•°è¡¨ï¼Œæ„å»ºå« P å€¼ä¸ LogWorth çš„è¾“å‡º
            coef_tbl = model_fit.summary().tables[1].copy()
            coef_tbl.columns = ["Coef.", "Std.Err.", "z", "P>|z|", "[0.025", "0.975]"]
            coef_tbl["P>|z|"] = pd.to_numeric(coef_tbl["P>|z|"], errors="coerce").fillna(1.0)
            coef_tbl["Response"] = y
            coef_tbl["Factor"] = coef_tbl.index
            coef_tbl["LogWorth"] = -np.log10(coef_tbl["P>|z|"].replace(0, 1e-16))
            param_coded_list.append(coef_tbl[["Response", "Factor", "Coef.", "P>|z|", "LogWorth"]])

            # ğŸ” å‚æ•°åæ ‡å‡†åŒ–ï¼ˆè§£ç ï¼‰
            X_mean = scaler.mean_
            X_scale = scaler.scale_
            uncoded = []

            for pname in coef_tbl.index:
                if pname == "Intercept":
                    continue
                try:
                    coef_coded = float(coef_tbl.loc[pname, "Coef."])
                except:
                    continue

                if pname.startswith("I("):
                    var = pname.split("(")[1].split("**")[0].strip()
                    if var not in predictors: continue
                    i = predictors.index(var)
                    beta_uncoded = coef_coded / (X_scale[i] ** 2)

                elif ":" in pname:
                    var1, var2 = pname.split(":")
                    if var1 not in predictors or var2 not in predictors: continue
                    i1, i2 = predictors.index(var1), predictors.index(var2)
                    beta_uncoded = coef_coded / (X_scale[i1] * X_scale[i2])

                else:
                    var = pname.strip()
                    if var not in predictors: continue
                    i = predictors.index(var)
                    beta_uncoded = coef_coded / X_scale[i]

                uncoded.append((pname, beta_uncoded))

            intercept_uncoded = y_true.mean()
            for pname, beta_uncoded in uncoded:
                if pname.startswith("I(") or ":" in pname: continue
                var = pname.strip()
                if var not in predictors: continue
                i = predictors.index(var)
                intercept_uncoded -= beta_uncoded * X_mean[i]

            uncoded.insert(0, ("Intercept", intercept_uncoded))
            uncoded_df = pd.DataFrame(uncoded, columns=["Factor", "Estimate"])
            uncoded_df["Response"] = y
            param_uncoded_list.append(uncoded_df)

            # ğŸ“ JMP é£æ ¼ LOFï¼šåŸºäº config_combo èšåˆåè®¡ç®— lack-of-fit F ç»Ÿè®¡é‡
            df_raw["_fitted"] = y_pred
            group_df = df_raw.groupby("Config_combo").agg(
                local_avg=(y, "mean"),
                fitted_val=("_fitted", "mean"),
                count=("Config_combo", "count")
            ).reset_index()

            ss_lack = (group_df["count"] * (group_df["local_avg"] - group_df["fitted_val"])**2).sum()
            df_lack = len(group_df) - model_fit.df_modelwc - 1
            df_merge = df_raw.merge(group_df[["Config_combo", "local_avg"]], on="Config_combo", how="left")
            ss_pure = ((df_merge[y] - df_merge["local_avg"])**2).sum()
            df_pure = df_merge.shape[0] - len(group_df)

            ms_lack = ss_lack / df_lack
            ms_pure = ss_pure / df_pure
            F_lof = ms_lack / ms_pure
            from scipy.stats import f as f_dist
            p_lof = 1 - f_dist.cdf(F_lof, df_lack, df_pure)

            lof_records.append({
                "Response": y,
                "DF_LackOfFit": df_lack,
                "SS_LackOfFit": ss_lack,
                "MS_LackOfFit": ms_lack,
                "DF_PureError": df_pure,
                "SS_PureError": ss_pure,
                "MS_PureError": ms_pure,
                "F_Ratio": F_lof,
                "p_Value": p_lof
            })

        except Exception as e:
            print(f"âŒ æ¨¡å‹æ‹Ÿåˆå¤±è´¥ - {y}: {e}")

    # === ğŸ” Console Diagnostic Summary ===
    print("\n\n============================== ğŸ“‹ JMP-style Diagnostic Summary ==============================")

    for diag, uncoded_df in zip(diagnostics_summary, param_uncoded_list):
        y = diag["Response"]
        print(f"\nâ–¶ Response Variable: {y}")
        print("-------------------------------------------------------------")
        print(f"Approximate RÂ²       : {diag['R2_Approximate']:.4f}")
        print(f"Adjusted RÂ² (approx.): {diag['Adjusted_R2_Approximate']:.4f}")
        print(f"RMSE                 : {diag['RMSE']:.4f}")
        print(f"Mean of Response     : {diag['Mean_Response']:.4f}")
        print(f"Observations         : {diag['Observations']}")

        # ğŸ”¬ Find LOF summary row
        lof_row = next((r for r in lof_records if r["Response"] == y), None)
        if lof_row:
            print("\nğŸ”¬ JMP-style Lack of Fit Table:")
            print(f"Lack of Fit     â€“ DF={lof_row['DF_LackOfFit']}, SS={lof_row['SS_LackOfFit']:.6f}, MS={lof_row['MS_LackOfFit']:.6f}")
            print(f"Pure Error      â€“ DF={lof_row['DF_PureError']}, SS={lof_row['SS_PureError']:.6f}, MS={lof_row['MS_PureError']:.6f}")
            print(f"Total Error     â€“ DF={lof_row['DF_LackOfFit'] + lof_row['DF_PureError']}, SS={(lof_row['SS_LackOfFit'] + lof_row['SS_PureError']):.6f}")
            print(f"F Ratio         : {lof_row['F_Ratio']:.4f}")
            print(f"p-value         : {lof_row['p_Value']:.5f}")
        
        # ğŸ“„ Uncoded Fixed Effects Table
        print("\nğŸ“„ Fixed Effects Estimates (Uncoded):")
        print(f"{'Estimate':>12s}    Term")
        for idx, row in uncoded_df.iterrows():
            print(f"{row['Estimate']:12.6f}    {row['Factor']}")

    # === Part 3a: æ¨¡å‹ç»“æœå¯¼å‡ºï¼ˆCSV å¤šæ–‡ä»¶ç‰ˆæœ¬ï¼‰===
    # ğŸ“Œ ç›®çš„ï¼šåœ¨ä¸ä¾èµ– xlsxwriter æ¨¡å—çš„æƒ…å†µä¸‹å¯¼å‡ºç»“æœï¼Œä¾¿äºåœ¨ JMP ä¸­ä½¿ç”¨ Python è„šæœ¬è¿è¡Œå¹¶è¯»å…¥ CSVã€‚
    # ğŸ” æœ¬è„šæœ¬å°†æ‰€æœ‰é‡è¦è¾“å‡ºå†™å…¥ç‹¬ç«‹ CSV æ–‡ä»¶ï¼ŒåŒ…æ‹¬å‚æ•°ä¼°è®¡ã€LogWorthã€è¯Šæ–­æŒ‡æ ‡ã€LOFã€æ®‹å·®å›¾æ•°æ®ç­‰ã€‚

    # ğŸ“ è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„
    os.makedirs(output_dir, exist_ok=True)

    # === âœ… åœ¨æ‰€æœ‰æ¨¡å‹æ„å»ºå®Œæ¯•åç»Ÿä¸€å¯¼å‡º fixed Intercept ===
    # ğŸ’¬ èƒŒæ™¯ï¼š
    # é»˜è®¤çš„ coded_parameters.csv ä¸­ Interceptï¼ˆÎ²â‚€ï¼‰å­—æ®µå¯¼å‡ºè‡ª model_fit.params["Intercept"]ï¼Œ
    # è€Œè¯¥å€¼é€šå¸¸åŒ…å«ç»„åˆ« shrinkageï¼ˆå³ group-level intercept correctionï¼‰ï¼Œéçº¯å›ºå®šé¡¹ï¼›
    #
    # ğŸ”¬ å¦‚æœç»§ç»­ä½¿ç”¨è¯¥ Interceptï¼Œä¼šå¯¼è‡´ predict_coded(...) çš„ç»“æœä¸ JMP Profiler äº§ç”Ÿæ˜æ˜¾åå·®ï¼ˆæœ€å¤šå¯è¾¾ 1.2+ï¼‰ï¼›
    # ğŸ“ˆ ä¸ºäº†ç¡®ä¿è¯„åˆ†ä¸æ¨èä¸ JMP ä¸€è‡´ï¼Œæˆ‘ä»¬éœ€å°†å…¶æ›¿æ¢ä¸º model_fit.fe_params["Intercept"] å¯¼å‡ºçš„å›ºå®šæˆªè·ã€‚
    #
    # âœ… æœ¬å‡½æ•°å°†ä¿®æ­£ Interceptï¼Œå¹¶è¿”å›ç”¨äº L/A/B æ‰“åˆ†çš„ Î² ç³»æ•°è¡¨ã€‚

    fixed_intercepts = []
    for y in response_vars:
        beta_0 = models[y].fe_params["Intercept"]
        fixed_intercepts.append({"Response": y, "Fixed_Intercept": beta_0})

    fixed_df = pd.DataFrame(fixed_intercepts)
    fixed_df.to_csv(os.path.join(output_dir, "fixed_intercepts.csv"), index=False)


    # 1ï¸âƒ£ LogWorth è¡¨
    effect_summary_all.to_csv(os.path.join(output_dir, "fullmodel_logworth.csv"), index=False)
    simplified_logworth_df.to_csv(os.path.join(output_dir, "simplified_logworth.csv"), index=False)

    # 2ï¸âƒ£ å‚æ•°ä¼°è®¡ï¼ˆCoded / Uncoded ç©ºé—´ï¼‰
    pd.concat(param_coded_list).to_csv(os.path.join(output_dir, "coded_parameters.csv"), index=False)
    pd.concat(param_uncoded_list).to_csv(os.path.join(output_dir, "uncoded_parameters.csv"), index=False)

    # 3ï¸âƒ£ æ¨¡å‹è¯Šæ–­æŒ‡æ ‡ï¼ˆå«è¿‘ä¼¼ RÂ² å’Œ Adjusted RÂ²ï¼‰
    # ğŸ“Œ æ³¨æ„ï¼šRÂ² æ˜¯åŸºäº MixedLM çš„é¢„æµ‹å€¼è¿‘ä¼¼æ¨ç®—ï¼ŒéåŸç”Ÿå±æ€§ã€‚
    diagnostics_df = pd.DataFrame(diagnostics_summary)
    diagnostics_df = diagnostics_df.rename(columns={
        "R2_Approximate": "R2_Approximate",
        "Adjusted_R2_Approximate": "Adjusted_R2_Approximate"
    })
    diagnostics_df.to_csv(os.path.join(output_dir, "diagnostics_summary.csv"), index=False)

    # 4ï¸âƒ£ JMP é£æ ¼ Lack-of-Fit åˆ†è§£è¡¨
    pd.DataFrame(lof_records).to_csv(os.path.join(output_dir, "JMP_style_lof.csv"), index=False)

    # 5ï¸âƒ£ å˜é‡æ ‡å‡†åŒ–ä¿¡æ¯ï¼ˆç”¨äºè§£ç ï¼‰
    pd.DataFrame({
        "Variable": predictors,
        "Mean": scaler.mean_,
        "StdDev": scaler.scale_
    }).to_csv(os.path.join(output_dir, "scaler.csv"), index=False)

    # 6ï¸âƒ£ æ¨¡å‹å…¬å¼æ–‡æœ¬ï¼ˆé€å“åº”å˜é‡ï¼‰
    with open(os.path.join(output_dir, "model_formulas.txt"), "w") as f:
        for y in response_vars:
            formula = f"{y} ~ " + " + ".join(simplified_factors)
            f.write(f"{y} formula:\n{formula}\n\n")

    # 7ï¸âƒ£ åŸºäº Mixed Model çš„é¢„æµ‹å€¼ & æ®‹å·®ï¼ˆè¾“å‡ºå›¾å½¢æ‰€ç”¨ CSVï¼‰
    # âš ï¸ æ³¨æ„ï¼šç”±äº MixedLM æ— å¸½å­çŸ©é˜µï¼Œæˆ‘ä»¬æ— æ³•è®¡ç®—çœŸå®çš„ studentized residualï¼›
    # âœ… æ­¤å¤„ä½¿ç”¨ RMSE å¯¹ residual è¿›è¡Œæ ‡å‡†åŒ–ï¼Œå½¢æˆ Pseudo Studentized Residualï¼Œä»…ä¾›è§†è§‰è¯Šæ–­ç”¨ã€‚
    # ğŸ“Œ å‡å·²æ ‡è®°å­—æ®µåä¸ºï¼šPseudo_Studentized_Residual

    for y in response_vars:
        try:
            # è·å–æ¨¡å‹é¢„æµ‹å€¼ï¼ˆç”± Part 2 çš„ MixedLM æ‹Ÿåˆè€Œæ¥ï¼‰
            model_fit = models[y]
            y_true = df[y]
            y_pred = model_fit.fittedvalues
            resid = y_true - y_pred

            # è¿‘ä¼¼ Studentized Residualï¼ˆæ®‹å·®é™¤ä»¥ RMSEï¼‰
            rmse = np.sqrt(np.mean(resid ** 2))
            pseudo_stud_resid = resid / rmse if rmse > 0 else resid

            df_out = pd.DataFrame({
                "Config_combo": df["Config_combo"],
                "Actual": y_true,
                "Predicted": y_pred,
                "Residual": resid,
                "Pseudo_Studentized_Residual": pseudo_stud_resid
            })
            df_out.index.name = "ID"

            out_path = os.path.join(output_dir, f"residual_data_{y}_from_MixedModel.csv")
            df_out.to_csv(out_path)

        except Exception as e:
            print(f"âŒ æ®‹å·®è¾“å‡ºå¤±è´¥ [{y}]: {e}")


    # 8ï¸âƒ£ å»ºæ¨¡è¾“å…¥æ•°æ®å¯¼å‡ºï¼ˆä¾› JMP ä½¿ç”¨ Fit Model è„šæœ¬ï¼‰
    # ğŸ“Œ è¾“å‡ºåŒ…å«å“åº”å˜é‡ + åŸå§‹å› å­åˆ—çš„å®Œæ•´è§‚æµ‹æ•°æ®è¡¨ï¼ˆæœªæ ‡å‡†åŒ–ï¼‰
    # âœ… æ–‡ä»¶å design_data.csv æ˜¯ JMP è„šæœ¬é»˜è®¤è¯»å–çš„æ•°æ®æº
    df_raw.to_csv(os.path.join(output_dir, "design_data.csv"), index=False)

    # === ğŸ“ è¾“å‡ºç»“æ„æ–¹å·®æ‘˜è¦è¡¨ï¼šmixed_model_variance_summary.csv ===
    df_var = pd.DataFrame(var_records)
    df_var.to_csv(os.path.join(output_dir, "mixed_model_variance_summary.csv"), index=False)

    # === ğŸ†• è¾“å‡ºæ ‡å‡†åŒ–ä¿¡æ¯è‡³ CSV (InputDataBrief.csv) ===

    brief_path = os.path.join(output_dir, "InputDataBrief.csv")
    brief_df = pd.DataFrame({
        "Variable": predictors,
        "Mean (after standardization)": df[predictors].mean().values,
        "StdDev (after standardization)": df[predictors].std(ddof=0).values,
        "Original Mean (X_mean)": scaler.mean_,
        "Original StdDev (X_std)": scaler.scale_
    })

    brief_df.to_csv(brief_path, index=False)
    # print(f"\nğŸ“¤ InputDataBrief.csv saved to: {brief_path}")

    print(f"\nâœ… æ‰€æœ‰å»ºæ¨¡ç»“æœå·²åŸºäº Mixed Model å¯¼å‡ºä¸º CSVï¼Œä¿å­˜åœ¨ï¼š{output_dir}")

# ç›´æ¥è¿è¡Œè„šæœ¬æ—¶çš„å…¥å£
if __name__ == "__main__":
    run_mixed_model_doe(
        r"C:\Zhanglei_Microsoft_Upgrade_by_20240905\Pytyon_Study_Local\Color_S2\DOEData_20250622.csv",
        r"C:\Zhanglei_Microsoft_Upgrade_by_20240905\Pytyon_Study_Local\Color_S2\DOE_MixedModel_Outputs"
    )

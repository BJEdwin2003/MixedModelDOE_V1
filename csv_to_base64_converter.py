"""
CSV to Base64 Converter Tool
ç”¨äºå°† CSV æ–‡ä»¶è½¬æ¢ä¸º Base64 ç¼–ç ï¼Œä¾› AI Foundry/Copilot Studio ä½¿ç”¨

ğŸ” å…³äºæ–‡ä»¶è·¯å¾„çš„å¤„ç†ï¼š
1. æ‰‹åŠ¨æŒ‡å®šè·¯å¾„ - ç”¨æˆ·è¾“å…¥å®Œæ•´æ–‡ä»¶è·¯å¾„
2. è‡ªåŠ¨æ‰«æè·¯å¾„ - ç¨‹åºè‡ªåŠ¨æŸ¥æ‰¾å½“å‰ç›®å½•çš„ CSV æ–‡ä»¶
3. API è‡ªåŠ¨å¤„ç† - é€šè¿‡ HTTP è¯·æ±‚ä¼ é€’ Base64 æ•°æ®ï¼Œæ— éœ€æœ¬åœ°è·¯å¾„

Author: Zhang Lei
Created: August 2025
"""

import base64
import os
import json
import glob

def list_csv_files_in_directory(directory="."):
    """
    åˆ—å‡ºæŒ‡å®šç›®å½•ä¸­çš„æ‰€æœ‰ CSV æ–‡ä»¶
    
    Args:
        directory (str): ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•
        
    Returns:
        list: CSV æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    csv_pattern = os.path.join(directory, "*.csv")
    csv_files = glob.glob(csv_pattern)
    return csv_files

def csv_to_base64(csv_file_path):
    """
    å°† CSV æ–‡ä»¶è½¬æ¢ä¸º Base64 ç¼–ç 
    
    Args:
        csv_file_path (str): CSV æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
        
    Returns:
        str: Base64 ç¼–ç çš„å­—ç¬¦ä¸²
    """
    try:
        print(f"ğŸ“ æ­£åœ¨è¯»å–æ–‡ä»¶ï¼š{csv_file_path}")
        with open(csv_file_path, 'rb') as file:
            csv_content = file.read()
            base64_encoded = base64.b64encode(csv_content).decode('utf-8')
            print(f"âœ… æ–‡ä»¶è¯»å–æˆåŠŸï¼Œå¤§å°ï¼š{len(csv_content)} å­—èŠ‚")
            print(f"ğŸ”„ Base64 ç¼–ç æˆåŠŸï¼Œé•¿åº¦ï¼š{len(base64_encoded)} å­—ç¬¦")
            return base64_encoded
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨ - {csv_file_path}")
        return None
    except PermissionError:
        print(f"âŒ é”™è¯¯ï¼šæ²¡æœ‰æƒé™è¯»å–æ–‡ä»¶ - {csv_file_path}")
        return None
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼šæ— æ³•è¯»å–æ–‡ä»¶ {csv_file_path}")
        print(f"ğŸ“ è¯¦ç»†é”™è¯¯ï¼š{str(e)}")
        return None

def create_ai_foundry_json(csv_file_path, response_columns="Lvalue,Avalue,Bvalue", 
                          predictors=None, threshold=1.5):
    """
    åˆ›å»º AI Foundry å…¼å®¹çš„ JSON è¯·æ±‚æ ¼å¼
    
    Args:
        csv_file_path (str): CSV æ–‡ä»¶è·¯å¾„
        response_columns (str): å“åº”å˜é‡ï¼ˆé€—å·åˆ†éš”ï¼‰
        predictors (str): é¢„æµ‹å˜é‡ï¼ˆé€—å·åˆ†éš”ï¼Œå¯é€‰ï¼‰
        threshold (float): LogWorth é˜ˆå€¼
        
    Returns:
        dict: AI Foundry è¯·æ±‚æ ¼å¼çš„å­—å…¸
    """
    base64_data = csv_to_base64(csv_file_path)
    if base64_data is None:
        return None
        
    request_json = {
        "data": base64_data,
        "response_column": response_columns,
        "threshold": threshold,
        "force_full_dataset": True
    }
    
    if predictors:
        request_json["predictors"] = predictors
        
    return request_json

def save_json_file(json_data, output_file_path):
    """
    ä¿å­˜ JSON æ•°æ®åˆ°æ–‡ä»¶
    
    Args:
        json_data (dict): è¦ä¿å­˜çš„ JSON æ•°æ®
        output_file_path (str): è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    try:
        with open(output_file_path, 'w', encoding='utf-8') as file:
            json.dump(json_data, file, indent=2, ensure_ascii=False)
        print(f"âœ… JSON æ–‡ä»¶å·²ä¿å­˜åˆ°ï¼š{output_file_path}")
    except Exception as e:
        print(f"âŒ ä¿å­˜ JSON æ–‡ä»¶å¤±è´¥ï¼š{str(e)}")

def main():
    """
    ä¸»å‡½æ•°ï¼šäº¤äº’å¼è½¬æ¢å·¥å…·
    """
    print("ğŸ”„ CSV è½¬ Base64 è½¬æ¢å·¥å…·")
    print("=" * 50)
    
    # ğŸ” è·¯å¾„å¤„ç†æ–¹å¼1ï¼šè‡ªåŠ¨æ‰«æå½“å‰ç›®å½•
    print("ğŸ“ æ­£åœ¨æ‰«æå½“å‰ç›®å½•çš„ CSV æ–‡ä»¶...")
    current_dir = os.getcwd()
    print(f"ğŸ“‚ å½“å‰å·¥ä½œç›®å½•ï¼š{current_dir}")
    
    csv_files = list_csv_files_in_directory(current_dir)
    
    if csv_files:
        print(f"\nğŸ“‹ å‘ç° {len(csv_files)} ä¸ª CSV æ–‡ä»¶ï¼š")
        for i, file in enumerate(csv_files, 1):
            filename = os.path.basename(file)
            filesize = os.path.getsize(file)
            print(f"   {i}. {filename} ({filesize} å­—èŠ‚)")
        
        # è®©ç”¨æˆ·é€‰æ‹©æ–‡ä»¶
        print(f"\nè¯·é€‰æ‹©è¦è½¬æ¢çš„æ–‡ä»¶ï¼š")
        print(f"1-{len(csv_files)}. é€‰æ‹©ä¸Šè¿°æ–‡ä»¶")
        print(f"0. æ‰‹åŠ¨è¾“å…¥æ–‡ä»¶è·¯å¾„")
        
        choice = input("è¯·è¾“å…¥é€‰æ‹©ï¼ˆ1-{} æˆ– 0ï¼‰ï¼š".format(len(csv_files))).strip()
        
        if choice == "0":
            # ğŸ” è·¯å¾„å¤„ç†æ–¹å¼2ï¼šæ‰‹åŠ¨è¾“å…¥è·¯å¾„
            csv_file = input("è¯·è¾“å…¥ CSV æ–‡ä»¶çš„å®Œæ•´è·¯å¾„ï¼š").strip()
        else:
            try:
                file_index = int(choice) - 1
                if 0 <= file_index < len(csv_files):
                    csv_file = csv_files[file_index]
                else:
                    print("âŒ é€‰æ‹©æ— æ•ˆ")
                    return
            except ValueError:
                print("âŒ è¾“å…¥æ— æ•ˆ")
                return
    else:
        print("âš ï¸ å½“å‰ç›®å½•æ²¡æœ‰æ‰¾åˆ° CSV æ–‡ä»¶")
        # ğŸ” è·¯å¾„å¤„ç†æ–¹å¼3ï¼šæ‰‹åŠ¨è¾“å…¥è·¯å¾„
        csv_file = input("è¯·è¾“å…¥ CSV æ–‡ä»¶çš„å®Œæ•´è·¯å¾„ï¼š").strip()
    
    if not csv_file:
        print("âŒ è¯·æä¾›æœ‰æ•ˆçš„æ–‡ä»¶è·¯å¾„")
        return
        
    if not os.path.exists(csv_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼š{csv_file}")
        return
    
    print(f"\nğŸ“ é€‰æ‹©çš„æ–‡ä»¶ï¼š{csv_file}")
    
    # è·å–å“åº”å˜é‡
    response_cols = input("è¯·è¾“å…¥å“åº”å˜é‡ï¼ˆé€—å·åˆ†éš”ï¼Œé»˜è®¤ï¼šLvalue,Avalue,Bvalueï¼‰ï¼š").strip()
    if not response_cols:
        response_cols = "Lvalue,Avalue,Bvalue"
    
    # è·å–é¢„æµ‹å˜é‡ï¼ˆå¯é€‰ï¼‰
    predictors = input("è¯·è¾“å…¥é¢„æµ‹å˜é‡ï¼ˆé€—å·åˆ†éš”ï¼Œå¯é€‰ï¼‰ï¼š").strip()
    if not predictors:
        predictors = None
    
    # è·å–é˜ˆå€¼
    threshold_input = input("è¯·è¾“å…¥ LogWorth é˜ˆå€¼ï¼ˆé»˜è®¤ï¼š1.5ï¼‰ï¼š").strip()
    try:
        threshold = float(threshold_input) if threshold_input else 1.5
    except ValueError:
        threshold = 1.5
        print("âš ï¸ é˜ˆå€¼è¾“å…¥æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼ 1.5")
    
    print("\nğŸ”„ æ­£åœ¨è½¬æ¢...")
    
    # æ–¹å¼1ï¼šè¾“å‡º Base64 å­—ç¬¦ä¸²
    base64_result = csv_to_base64(csv_file)
    if base64_result:
        print(f"\nâœ… Base64 ç¼–ç æˆåŠŸï¼")
        
        # ä¿å­˜ Base64 åˆ°æ–‡ä»¶
        base64_file = csv_file.replace('.csv', '_base64.txt')
        with open(base64_file, 'w') as f:
            f.write(base64_result)
        print(f"ğŸ’¾ Base64 å­—ç¬¦ä¸²å·²ä¿å­˜åˆ°ï¼š{base64_file}")
    
    # æ–¹å¼2ï¼šåˆ›å»º AI Foundry JSON æ ¼å¼
    json_result = create_ai_foundry_json(csv_file, response_cols, predictors, threshold)
    if json_result:
        json_file = csv_file.replace('.csv', '_ai_foundry_request.json')
        save_json_file(json_result, json_file)
        
        print(f"\nğŸ“‹ AI Foundry è¯·æ±‚æ ¼å¼é¢„è§ˆï¼š")
        print(f"   data: [Base64 ç¼–ç çš„ CSV æ•°æ® - {len(json_result['data'])} å­—ç¬¦]")
        print(f"   response_column: {json_result['response_column']}")
        print(f"   threshold: {json_result['threshold']}")
        if 'predictors' in json_result:
            print(f"   predictors: {json_result['predictors']}")
    
    print(f"\nğŸ¯ ä½¿ç”¨è¯´æ˜ï¼š")
    print(f"1. å°† Base64 å­—ç¬¦ä¸²å¤åˆ¶åˆ° AI Agent èŠå¤©çª—å£")
    print(f"2. æˆ–è€…å°†æ•´ä¸ª JSON æ–‡ä»¶å†…å®¹å‘é€ç»™ API")
    print(f"3. API ç«¯ç‚¹ï¼šhttps://mixedmodeldoe-v1.onrender.com/api/DoeAnalysis")
    
    print(f"\nğŸ“ è·¯å¾„è¯´æ˜ï¼š")
    print(f"ğŸ“‚ å·¥ä½œç›®å½•ï¼š{current_dir}")
    print(f"ğŸ“ æºæ–‡ä»¶ï¼š{csv_file}")
    print(f"ğŸ’¾ Base64æ–‡ä»¶ï¼š{base64_file}")
    print(f"ğŸ“‹ JSONæ–‡ä»¶ï¼š{json_file}")

if __name__ == "__main__":
    main()
